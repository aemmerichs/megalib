module spark.SparkSQL

import spark.Spark


/*
Spark SQL is a Spark module for structured data processing. It provides an interface provides more informations about both the strucuture of the data and the computation beeing performed.
*/
SparkSQL : Technology;
    ="http://spark.apache.org/docs/latest/sql-programming-guide.html";
    uses SQL;
    uses ResilientDistributedDatasets;
    partOf Spark.

    
/*
Spark implements DataFrames under the hood. Those implementation is following a grammar and hence
is an own language.
*/
ScalaDataFrames : DatabaseLanguage;
    ="https://databricks.com/blog/2015/02/17/introducing-dataframes-in-spark-for-large-scale-data-science.html".
    

/*
A concrete dataFrame created from Rdds, a resulting data frame from a SQL operation and finally a SQL statement.
*/
?dataFrame : Artifact;
    elementOf ScalaDataFrames;
    hasRole Database;
    manifestsAs Transient;
    deployedAt ?SparkCluster.
?resultingDataFrame : Artifact;
    elementOf ScalaDataFrames;
    hasRole Database;
    manifestsAs Transient;
    deployedAt ?SparkCluster.
?sqlStatement : Artifact;
    elementOf SQLQuery;
    hasRole Query;
    manifestsAs Transient;
    deployedAt ?SparkCluster.


/*
Scala data frames can be created form existing RDDS
*/
createFrame : ResilientDistributedDatasets -> ScalaDataFrames.
createFrame(?rddObjects) |-> ?dataFrame.

/*
SparkSQL let the developer either maninpulate the data by entering SQL queries or by applying SQL like
function calls. Both will be abstracted using SQL language. The result of the operation is a manipulated data frame.
*/
dataFramesOperations : ScalaDataFrames # SQL -> ScalaDataFrames.
dataFramesOperations(?dataFrame, ?sqlStatement) |-> ?resultingDataFrame.

SparkSQL implements ScalaDataFrames;
         facilitates DataFrame;
         implements createFrame;
         implements dataFramesOperations.


